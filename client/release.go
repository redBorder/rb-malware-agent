// Copyright (C) 2016 Eneo Tecnologia S.L.
// Diego Fern√°ndez Barrera <bigomby@gmail.com>
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, either version 3 of the
// License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

package client

import (
	"bufio"
	"encoding/json"
	"errors"
	"io"
	"os"
	"strconv"
	"strings"
	"regexp"
	"github.com/Sirupsen/logrus"
)

/////////////////
// Structures  //
/////////////////

// InstanceData contains the path for the files where store gathered data from
// the API.
type InstanceData struct {
	MinScore int

	HashBlacklistPath string
	IPBlacklistPath   string
	HashWhitelistPath string
	IPWhitelistPath   string
	URLBlacklistPath  string

	hashBlacklist map[string]int
	ipBlacklist   map[string]int
	hashWhitelist map[string]int
	ipWhitelist   map[string]int
	URLBlacklist  map[string]int
}

// Release contains information about the score of IP addresses and files previously
// analyzed. Only stores entries with a score greater than minScore unless
// "whitelist" flag is set to "true"
type Release struct {
	Revision      int
	Incremental   int
	apiClient     ApiClient
	instancesData []InstanceData
	lastSid		  int
}

// NewRelease creates a new Release object
func NewRelease(apiClient ApiClient, instancesData []InstanceData, lastSid int) Release {
	r := Release{
		Revision:      0,
		Incremental:   0,
		instancesData: instancesData,
		apiClient:     apiClient,
		lastSid:       lastSid,
	}

	for i := 0; i < len(instancesData); i++ {
		instancesData[i].hashBlacklist = make(map[string]int)
		instancesData[i].ipBlacklist = make(map[string]int)
		instancesData[i].hashWhitelist = make(map[string]int)
		instancesData[i].ipWhitelist = make(map[string]int)
		instancesData[i].URLBlacklist = make(map[string]int)
	}

	return r
}

// Reload updates internal options with new provided arguments
func (r *Release) Reload(minScore float64, instanceData []InstanceData) {
	r.instancesData = instanceData
	r.Init()
}

// Init gets the Total and then the Incremental if necessary
func (r *Release) Init() (err error) {

	// Get TOTAL and obtain the last release
	total, err := r.apiClient.GetTotal()
	if err != nil {
		err = errors.New("Error getting TOTAL: " + err.Error())
		return
	}
	defer total.Close()

	revision, incremental, err := r.process(total, false)
	if err != nil {
		err = errors.New("Error processing TOTAL: " + err.Error())
		return
	}

	if incremental > 0 {

		// Get INCREMENTAL
		delta, err := r.apiClient.GetIncremental(revision, incremental)
		if err != nil {
			err = errors.New("Error getting INCREMENTAL: " + err.Error())
			return err
		}
		defer delta.Close()

		if _, _, err := r.process(delta, true); err != nil {
			err = errors.New("Error processing INCREMENTAL: " + err.Error())
			return err
		}
	}

	logrus.Infof("Initialized local data to: %d.%d", revision, incremental)
	r.Revision = revision
	r.Incremental = incremental

	return
}

// Update checks the current version and updates the local information of the
// release if necessary
func (r *Release) Update() (changed bool, err error) {
	revision, incremental, err := r.apiClient.GetCurrentRelease()
	if err != nil {
		err = errors.New("Error getting current release: " + err.Error())
		return
	}

	if r.Revision != revision {
		// Mayor update, discard all the data we have
		changed = true

		// Get TOTAL and obtain the last release
		total, err := r.apiClient.GetTotal()
		if err != nil {
			return changed, errors.New("Error getting TOTAL: " + err.Error())
		}
		defer total.Close()

		revision, incremental, err := r.process(total, false)
		if err != nil {
			return changed, errors.New("Error processing TOTAL: " + err.Error())
		}

		r.Revision = revision
		r.Incremental = 0

		// Get INCREMENTAL
		delta, err := r.apiClient.GetIncremental(revision, incremental)
		if err != nil {
			return changed, errors.New("Error getting INCREMENTAL: " + err.Error())
		}
		defer delta.Close()

		if _, _, err := r.process(delta, true); err != nil {
			return changed, errors.New("Error processing INCREMENTAL: " + err.Error())
		}

		r.Incremental = incremental

		logrus.Infof("Updated local data to: %d.%d", revision, incremental)
	} else if r.Incremental != incremental {
		// Minor update
		changed = true

		// Get INCREMENTAL
		delta, err := r.apiClient.GetIncremental(revision, incremental)
		if err != nil {
			return changed, errors.New("Error getting INCREMENTAL: " + err.Error())
		}
		defer delta.Close()

		if _, _, err := r.process(delta, true); err != nil {
			return changed, errors.New("Error processing INCREMENTAL: " + err.Error())
		}

		r.Incremental = incremental
		logrus.Infof("Updated local data to: %d.%d", revision, incremental)
	}

	return changed, err
}

func (r *Release) generateRule(url string) string {
	sid := r.lastSid
	r.lastSid++
	// Extract hostname and URI
	hostRegex := regexp.MustCompile(`^(https?://[^/]+)`)
	uriRegex := regexp.MustCompile(`^(https?://[^/]+)?(.*)`)
	hostMatch := hostRegex.FindStringSubmatch(url)
	host := hostMatch[1]
	uriMatch := uriRegex.FindStringSubmatch(url)
	uri := uriMatch[2]

	// Replace "https://" or "http://" in host
	host = strings.TrimPrefix(host, "https://")
	host = strings.TrimPrefix(host, "http://")

	rule := "drop tcp any any -> any any (msg:\"Block URL pattern and hostname\"; content:\"" + uri + "\"; http_uri; content:\"Host: " + host + "\"; http_header; sid:" + strconv.Itoa(sid) + "; rev:1;)"
	return rule
}

// Dump saves the information to a file
func (r *Release) Dump() error {
	for i := 0; i < len(r.instancesData); i++ {
		hashBlackListPath := r.instancesData[i].HashBlacklistPath
		hashWhiteListPath := r.instancesData[i].HashWhitelistPath
		ipBlacklistPath := r.instancesData[i].IPBlacklistPath
		ipWhitelistPath := r.instancesData[i].IPWhitelistPath
		urlBlacklistPath := r.instancesData[i].URLBlacklistPath

		hashBlackList := r.instancesData[i].hashBlacklist
		hashWhiteList := r.instancesData[i].hashWhitelist
		ipBlacklist := r.instancesData[i].ipBlacklist
		ipWhitelist := r.instancesData[i].ipWhitelist
		URLBlacklist := r.instancesData[i].URLBlacklist

		// Hashes Black List
		if len(hashBlackListPath) > 0 {
			hashBlacklistFile, err := os.Create(hashBlackListPath)
			if err != nil {
				return errors.New("Error creating hashes blacklist: " + err.Error())
			}
			defer hashBlacklistFile.Close()

			hashBlacklistWriter := bufio.NewWriter(hashBlacklistFile)

			for k := range hashBlackList {
				if _, err := hashBlacklistWriter.WriteString(k + "\n"); err != nil {
					return errors.New("Error storing hash on blacklist: " + err.Error())
				}
			}
			if err := hashBlacklistWriter.Flush(); err != nil {
				return errors.New("Error flushing on hash blacklist: " + err.Error())
			}
		}

		// Hashes White List
		if len(hashWhiteListPath) > 0 {
			hashWhitelistFile, err := os.Create(hashWhiteListPath)
			if err != nil {
				return errors.New("Error creating hashes whitelist: " + err.Error())
			}
			defer hashWhitelistFile.Close()

			hashWhitelistWriter := bufio.NewWriter(hashWhitelistFile)

			// Iterate the hashmap and save to a file
			for k := range hashWhiteList {
				if _, err := hashWhitelistWriter.WriteString(k + "\n"); err != nil {
					return errors.New("Error storing hash on whitelist: " + err.Error())
				}
			}
			if err := hashWhitelistWriter.Flush(); err != nil {
				return errors.New("Error flushing on hash blacklist: " + err.Error())
			}
		}

		// IPs Black List
		if len(ipBlacklistPath) > 0 {
			ipBlacklistFile, err := os.Create(ipBlacklistPath)
			if err != nil {
				return errors.New("Error creating IP blacklist" + err.Error())
			}
			defer ipBlacklistFile.Close()

			ipBlacklistWriter := bufio.NewWriter(ipBlacklistFile)

			for k := range ipBlacklist {
				if _, err := ipBlacklistWriter.WriteString(k + "\n"); err != nil {
					return errors.New("Error storing IP on blacklist: " + err.Error())
				}
			}
			if err := ipBlacklistWriter.Flush(); err != nil {
				return errors.New("Error flushing on IP blacklist: " + err.Error())
			}
		}

		// IPs White List
		if len(ipWhitelistPath) > 0 {
			ipWhitelistFile, err := os.Create(ipWhitelistPath)
			if err != nil {
				return errors.New("Error creating IP whitelist: " + err.Error())
			}
			defer ipWhitelistFile.Close()

			ipWhitelistWriter := bufio.NewWriter(ipWhitelistFile)

			// Iterate the hashmap and save to a file
			for k := range ipWhitelist {
				if _, err := ipWhitelistWriter.WriteString(k + "\n"); err != nil {
					return errors.New("Error storing IP on whitelist: " + err.Error())
				}
			}
			if err := ipWhitelistWriter.Flush(); err != nil {
				return errors.New("Error flushing on IP whitelist: " + err.Error())
			}
		}

		// URL Black list
		if len(urlBlacklistPath) > 0 {
			urlBlacklistFile, err := os.Create(urlBlacklistPath)
			if err != nil {
				return errors.New("Error creating URL blacklist: " + err.Error())
			}
			defer urlBlacklistFile.Close()

			urlBlacklisWriter := bufio.NewWriter(urlBlacklistFile)

			// Iterate the hashmap and save to a file
			for k := range URLBlacklist {
				if _, err := urlBlacklisWriter.WriteString(r.generateRule(k) + "\n"); err != nil {
					return errors.New("Error storing URL on blacklist: " + err.Error())
				}
			}
			if err := urlBlacklisWriter.Flush(); err != nil {
				return errors.New("Error flushing on URL blacklist: " + err.Error())
			}
		}
	}

	return nil
}



// process converts a JSON Array to a hashmap with "hash/IP" as key and "score" as value.
func (r *Release) process(body io.ReadCloser, copyMap bool) (revision, incremental int, err error) {
	type ParsedBody struct {
		Hash  string `json:"hash"`
		Score int    `json:"score"`
		IP    string `json:"ip"`
		URL   string `json:"url"`
	}

	ipBlacklist := []map[string]int{}
	ipWhitelist := []map[string]int{}
	hashBlacklist := []map[string]int{}
	hashWhitelist := []map[string]int{}
	URLBlacklist := []map[string]int{}
	// Make a local copy of the map
	for i := 0; i < len(r.instancesData); i++ {
		ipBlacklist = append(ipBlacklist, make(map[string]int))
		ipWhitelist = append(ipWhitelist, make(map[string]int))
		hashBlacklist = append(hashBlacklist, make(map[string]int))
		hashWhitelist = append(hashWhitelist, make(map[string]int))
		URLBlacklist = append(URLBlacklist, make(map[string]int))
		if copyMap {
			for k, v := range r.instancesData[i].ipBlacklist {
				ipBlacklist[i][k] = v
			}

			for k, v := range r.instancesData[i].ipWhitelist {
				ipWhitelist[i][k] = v
			}

			for k, v := range r.instancesData[i].hashBlacklist {
				hashBlacklist[i][k] = v
			}

			for k, v := range r.instancesData[i].hashWhitelist {
				hashWhitelist[i][k] = v
			}

			for k, v := range r.instancesData[i].URLBlacklist {
				URLBlacklist[i][k] = v
			}
		}
	}

	// Let the parsing begin!
	dec := json.NewDecoder(body)

	// Read open bracket
	if _, err = dec.Token(); err != nil {
		return
	}
	
	//Reverse decoding to correctly read data from rb-reputation server

	var d json.Token
	d, err = dec.Token()
	if err != nil {
		return
	}

	if d == "last_release" {
		var strVersion string
		if err = dec.Decode(&strVersion); err != nil {
			return
		}
		version := strings.Split(strVersion, ".")

		revision, err = strconv.Atoi(version[0])
		if err != nil {
			return
		}

		incremental, err = strconv.Atoi(version[1])
		if err != nil {
			return
		}
	}

	for d != "data" {
		d, err = dec.Token()
		if err != nil {
			return
		}
	}

	// Read array token
	if _, err = dec.Token(); err != nil {
		return
	}

	// While the array contains values
	for dec.More() {

		// Decode an array value
		var parsed ParsedBody
		if err = dec.Decode(&parsed); err != nil {
			return
		}

		if len(parsed.Hash) > 0 {
			for i := 0; i < len(r.instancesData); i++ {
				if parsed.Score < 0 {
					switch parsed.Score {
					case -1: // Unknown
						if hashWhitelist != nil {
							hashWhitelist[i][parsed.Hash] = parsed.Score
							delete(hashBlacklist[i], parsed.Hash)
						}
						break
					case -2: // Force whitelist
						if hashWhitelist != nil {
							hashWhitelist[i][parsed.Hash] = parsed.Score
							delete(hashBlacklist[i], parsed.Hash)
						}
						break
					case -3: // Force blacklist
						hashBlacklist[i][parsed.Hash] = parsed.Score
						delete(hashWhitelist[i], parsed.Hash)
						break
					}
					// Add to blacklist
				} else if parsed.Score >= r.instancesData[i].MinScore {
					hashBlacklist[i][parsed.Hash] = parsed.Score
					delete(hashWhitelist[i], parsed.Hash)
					// Add to whitelist
				} else if hashWhitelist != nil {
					hashWhitelist[i][parsed.Hash] = parsed.Score
					delete(hashBlacklist[i], parsed.Hash)
				}
			}
		}

		if len(parsed.IP) > 0 {
			for i := 0; i < len(r.instancesData); i++ {
				if parsed.Score < 0 {
					switch parsed.Score {
					case -2: // Force whitelist
						if ipWhitelist != nil {
							ipWhitelist[i][parsed.IP] = parsed.Score
							delete(ipBlacklist[i], parsed.IP)
						}
						break
					case -3: // Force blacklist
						ipBlacklist[i][parsed.IP] = parsed.Score
						delete(ipWhitelist[i], parsed.IP)
						break
					}
				} else if parsed.Score >= r.instancesData[i].MinScore {
					ipBlacklist[i][parsed.IP] = parsed.Score
					delete(ipWhitelist[i], parsed.IP)
				} else if ipWhitelist != nil {
					ipWhitelist[i][parsed.IP] = parsed.Score
					delete(ipBlacklist[i], parsed.IP)
				}
			}
		}

		if len(parsed.URL) > 0 {
			for i := 0; i < len(r.instancesData); i++ {
				if parsed.Score >= r.instancesData[i].MinScore {
					URLBlacklist[i][parsed.URL] = parsed.Score
				}
				if parsed.Score == -3 {
					URLBlacklist[i][parsed.URL] = parsed.Score
				}
			}
		}
	}

	// Read closing array
	if _, err = dec.Token(); err != nil {
		return
	}

	_, err = dec.Token()
	if err != nil {
		return
	}

	// If there are no errors then we commit changes on the map
	for i := 0; i < len(r.instancesData); i++ {
		r.instancesData[i].hashBlacklist = hashBlacklist[i]
		r.instancesData[i].hashWhitelist = hashWhitelist[i]
		r.instancesData[i].ipBlacklist = ipBlacklist[i]
		r.instancesData[i].ipWhitelist = ipWhitelist[i]
		r.instancesData[i].URLBlacklist = URLBlacklist[i]
	}

	return
}
